{
 "metadata": {
  "name": "",
  "signature": "sha256:664fa96e705ee1b2a2b1f99e38f9cd3163eb64125b3ba04a147e64e5e312290f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is equivalent to the `demo-word.sh`, `demo-analogy.sh` and `demo-classes.sh` from Google."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download some data, for example: [http://mattmahoney.net/dc/text8.zip](http://mattmahoney.net/dc/text8.zip)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import word2vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that this could take a long time depending on the parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec.word2vec('/Users/danielfrg/Downloads/text8', '/Users/danielfrg/Downloads/text8.bin', size=500, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That generated a `text8.bin` file containing the word vectors in a binary format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec.word2clusters('/Users/danielfrg/Downloads/text8', '/Users/danielfrg/Downloads/text8-clusters.txt', 100, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Word2vec"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We import the binary file created above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import word2vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = word2vec.load('/Users/danielfrg/Downloads/text8.bin')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take a look at the vocabulaty as a numpy array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array(['</s>', 'the', 'of', ..., 'bredon', 'skirting', 'santamaria'], \n",
        "      dtype='|S29')"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or take a look at the whole matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.l2norm.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(71291, 500)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.l2norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([[ -8.04771730e-02,   7.41668053e-02,   3.94218085e-02, ...,\n",
        "          7.98777888e-05,  -4.56608131e-02,  -1.40703583e-02],\n",
        "       [  5.92547082e-03,  -3.62639188e-02,  -3.01528642e-02, ...,\n",
        "         -4.86146612e-02,  -4.98366157e-02,   6.96591491e-04],\n",
        "       [ -3.02511420e-02,  -7.78638865e-04,   3.46132433e-02, ...,\n",
        "         -4.86108820e-03,   2.14688921e-02,  -2.20346024e-02],\n",
        "       ..., \n",
        "       [  5.68729237e-02,   2.25560366e-02,   2.55435588e-03, ...,\n",
        "         -8.70379062e-03,   3.58847830e-02,  -8.52748073e-03],\n",
        "       [  5.42321520e-02,   3.67840924e-02,   4.75219090e-02, ...,\n",
        "         -7.86100378e-02,   1.93014606e-02,  -7.80279571e-02],\n",
        "       [  9.05367106e-03,   1.57720178e-02,   2.60828559e-02, ...,\n",
        "         -1.93802027e-02,   5.45833808e-02,   1.84527213e-02]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can retreive the vector of individual words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model['dog'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(500,)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model['dog'][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([-0.06788083,  0.00600385, -0.01500341, -0.02120764,  0.02870771,\n",
        "        0.04961894,  0.0066967 , -0.03564264, -0.01237975, -0.00889487])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can do simple queries to retreive words similar to \"socks\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.cosine('socks')\n",
      "indexes, metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(array([19011, 24617, 35915, 13879, 14912, 12272, 33061, 13959, 11697, 65601]),\n",
        " array([ 0.6070896 ,  0.59497365,  0.58520327,  0.57883376,  0.57768822,\n",
        "         0.56022113,  0.55350533,  0.54919883,  0.54867936,  0.54830028]))"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This returned a tuple with 2 items:\n",
      "1. numpy array with the indexes of the similar words in the vocabulary\n",
      "2. numpy array with cosine similarity to each word"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its possible to get the words of those indexes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab[indexes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array(['sleeves', 'bump', 'bumper', 'pants', 'nails', 'boots', 'paws',\n",
        "       'smile', 'jacket', 'fuckin'], \n",
        "      dtype='|S29')"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a helper function to create a combined response"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([['sleeves', '0.607089604364'],\n",
        "       ['bump', '0.594973645262'],\n",
        "       ['bumper', '0.585203273424'],\n",
        "       ['pants', '0.578833760779'],\n",
        "       ['nails', '0.577688223906'],\n",
        "       ['boots', '0.56022112844'],\n",
        "       ['paws', '0.553505334'],\n",
        "       ['smile', '0.549198830932'],\n",
        "       ['jacket', '0.548679363251'],\n",
        "       ['fuckin', '0.548300278789']], \n",
        "      dtype='|S32')"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With that matrix is easy to make it a pure python response:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics).tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[['sleeves', '0.607089604364'],\n",
        " ['bump', '0.594973645262'],\n",
        " ['bumper', '0.585203273424'],\n",
        " ['pants', '0.578833760779'],\n",
        " ['nails', '0.577688223906'],\n",
        " ['boots', '0.56022112844'],\n",
        " ['paws', '0.553505334'],\n",
        " ['smile', '0.549198830932'],\n",
        " ['jacket', '0.548679363251'],\n",
        " ['fuckin', '0.548300278789']]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analogies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
      "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'], n=10)\n",
      "indexes, metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(array([  903,  6691, 15532,  4660,  8342,  1151,  2880,  4000, 34567, 40305]),\n",
        " array([ 0.18921752,  0.18831402,  0.18698359,  0.18164541,  0.17925267,\n",
        "         0.17632742,  0.17123332,  0.1707954 ,  0.16959674,  0.16948624]))"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([['queen', '0.189217519719'],\n",
        "       ['eldest', '0.188314019861'],\n",
        "       ['jadwiga', '0.186983594841'],\n",
        "       ['heir', '0.181645414458'],\n",
        "       ['illegitimate', '0.179252667545'],\n",
        "       ['daughter', '0.176327422262'],\n",
        "       ['ruler', '0.171233316248'],\n",
        "       ['viii', '0.170795404419'],\n",
        "       ['haakon', '0.169596742914'],\n",
        "       ['wladislaus', '0.169486240841']], \n",
        "      dtype='|S32')"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Clusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = word2vec.load_clusters('/Users/danielfrg/Downloads/text8-clusters.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see get the cluster number for individual words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters['dog']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "64"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see get all the words grouped on an specific cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters.get_words_on_cluster(90).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(1079,)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters.get_words_on_cluster(90)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array(['family', 'black', 'white', 'red', 'species', 'green', 'animals',\n",
        "       'tree', 'fish', 'wild'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can add the clusters to the word2vec model and generate a response that includes the clusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.clusters = clusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.analogy(pos=['paris', 'germany'], neg=['france'], n=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([['berlin', '0.209083618184', '35'],\n",
        "       ['munich', '0.199203766066', '35'],\n",
        "       ['vienna', '0.190025905145', '35'],\n",
        "       ['dresden', '0.180987005405', '35'],\n",
        "       ['leipzig', '0.180608823629', '18'],\n",
        "       ['frankfurt', '0.177233975999', '35'],\n",
        "       ['zurich', '0.170511424652', '35'],\n",
        "       ['moscow', '0.161529124671', '42'],\n",
        "       ['budapest', '0.157526146318', '35'],\n",
        "       ['bonn', '0.156986777145', '35']], \n",
        "      dtype='|S32')"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}