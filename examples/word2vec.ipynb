{
 "metadata": {
  "name": "",
  "signature": "sha256:089268750ec2e8c515cb4b73119b362c26adb5abf3f8a45eb687f42489742b33"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is equivalent to the `demo-word.sh`, `demo-analogy.sh` and `demo-classes.sh` from Google."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download some data, for example: [http://mattmahoney.net/dc/text8.zip](http://mattmahoney.net/dc/text8.zip)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import word2vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that this could take a long time depending on the parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec.word2vec('/Users/danielfrg/Downloads/text8', '/Users/danielfrg/Downloads/text8.bin', size=500, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That generated a `text8.bin` file containing the word vectors in a binary format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec.word2clusters('/Users/danielfrg/Downloads/text8', '/Users/danielfrg/Downloads/text8-clusters.txt', 100, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Word2vec"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We import the binary file created above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import word2vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = word2vec.load('/Users/danielfrg/Downloads/text8.bin')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take a look at the vocabulaty as a numpy array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array(['</s>', 'the', 'of', ..., 'bredon', 'skirting', 'santamaria'], \n",
        "      dtype='|S29')"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or take a look at the whole matrix"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.l2norm.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(71291, 500)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.l2norm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([[ -8.04771730e-02,   7.41668053e-02,   3.94218085e-02, ...,\n",
        "          7.98777888e-05,  -4.56608131e-02,  -1.40703583e-02],\n",
        "       [ -2.11432448e-02,   9.82087078e-03,  -6.73340368e-02, ...,\n",
        "         -9.52587061e-03,   6.76372060e-02,  -2.80742340e-02],\n",
        "       [ -8.16928088e-02,  -4.73127885e-02,  -9.90642228e-03, ...,\n",
        "         -6.13554879e-02,   3.42566312e-02,  -1.84423437e-02],\n",
        "       ..., \n",
        "       [  1.37167418e-01,  -8.04482882e-02,  -2.06031635e-02, ...,\n",
        "          4.17529340e-02,   6.07516252e-02,  -4.32103567e-04],\n",
        "       [ -3.70382995e-02,   4.79047679e-02,   7.81221229e-02, ...,\n",
        "          1.99350513e-02,  -1.59376685e-02,   4.85018960e-02],\n",
        "       [  3.85962688e-02,  -8.42366097e-02,  -3.06704605e-02, ...,\n",
        "          4.75629442e-02,   1.00591795e-01,   4.83790655e-02]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can retreive the vector of individual words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model['dog'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(500,)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model['dog'][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([-0.00274646,  0.02463897,  0.10761718, -0.05895592, -0.03271349,\n",
        "       -0.07785388,  0.08927545,  0.03262163, -0.07948719, -0.02543542])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can do simple queries to retreive words similar to \"socks\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.cosine('socks')\n",
      "indexes, metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(array([19011, 14017, 58953, 27316, 18908, 28569, 16350, 11233, 56490, 13651]),\n",
        " array([ 0.54017292,  0.53926796,  0.52692976,  0.50444643,  0.50283539,\n",
        "         0.49999057,  0.49860943,  0.49053641,  0.48864478,  0.48367677]))"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This returned a tuple with 2 items:\n",
      "1. numpy array with the indexes of the similar words in the vocabulary\n",
      "2. numpy array with cosine similarity to each word"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its possible to get the words of those indexes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.vocab[indexes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array(['sleeves', 'hats', 'ultramarine', 'sandals', 'tab', 'paw', 'trash',\n",
        "       'shorts', 'facemask', 'shirts'], \n",
        "      dtype='|S29')"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a helper function to create a combined response: a numpy [record array](http://docs.scipy.org/doc/numpy/user/basics.rec.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "rec.array([('sleeves', 0.5401729152039105), ('hats', 0.5392679636346274),\n",
        "       ('ultramarine', 0.5269297572306646), ('sandals', 0.504446430836469),\n",
        "       ('tab', 0.5028353863542001), ('paw', 0.49999056895304994),\n",
        "       ('trash', 0.4986094337927054), ('shorts', 0.4905364103964152),\n",
        "       ('facemask', 0.48864477661786676), ('shirts', 0.4836767716852113)], \n",
        "      dtype=[('word', 'S29'), ('metric', '<f8')])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With that numpy array is easy to make it a pure python response:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics).tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[('sleeves', 0.5401729152039105),\n",
        " ('hats', 0.5392679636346274),\n",
        " ('ultramarine', 0.5269297572306646),\n",
        " ('sandals', 0.504446430836469),\n",
        " ('tab', 0.5028353863542001),\n",
        " ('paw', 0.49999056895304994),\n",
        " ('trash', 0.4986094337927054),\n",
        " ('shorts', 0.4905364103964152),\n",
        " ('facemask', 0.48864477661786676),\n",
        " ('shirts', 0.4836767716852113)]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analogies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
      "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'], n=10)\n",
      "indexes, metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(array([23854, 26212, 44671, 12268, 40095, 17268, 11988, 24090, 46798,  6691]),\n",
        " array([ 0.19452381,  0.19448256,  0.188233  ,  0.18697777,  0.18668261,\n",
        "         0.18502419,  0.18436359,  0.18426492,  0.1835339 ,  0.18244998]))"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "rec.array([('hohenstaufen', 0.1945238062005651),\n",
        "       ('boleslaus', 0.19448255633005604), ('yorkist', 0.1882330035574516),\n",
        "       ('sigismund', 0.1869777650493646),\n",
        "       ('montferrat', 0.18668261051548574),\n",
        "       ('antiochus', 0.18502418620989053),\n",
        "       ('matilda', 0.18436359238013167), ('ethelred', 0.1842649217059812),\n",
        "       ('jotham', 0.18353389808009282), ('eldest', 0.1824499831769159)], \n",
        "      dtype=[('word', 'S29'), ('metric', '<f8')])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Clusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = word2vec.load_clusters('/Users/danielfrg/Downloads/text8-clusters.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see get the cluster number for individual words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters['dog']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "90"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see get all the words grouped on an specific cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters.get_words_on_cluster(90).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(621,)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters.get_words_on_cluster(90)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array(['species', 'brown', 'tree', 'dog', 'wild', 'bear', 'birds', 'genus',\n",
        "       'giant', 'bird'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can add the clusters to the word2vec model and generate a response that includes the clusters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.clusters = clusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, metrics = model.analogy(pos=['paris', 'germany'], neg=['france'], n=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.generate_response(indexes, metrics)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "rec.array([('munich', 0.20347299928721563, 81),\n",
        "       ('berlin', 0.2008978004737616, 81),\n",
        "       ('dresden', 0.18892079351004537, 81),\n",
        "       ('leipzig', 0.18778487561238122, 18),\n",
        "       ('bonn', 0.17936584517697501, 33),\n",
        "       ('vienna', 0.17760100356371242, 35),\n",
        "       ('frankfurt', 0.17724416312616964, 81),\n",
        "       ('calw', 0.17603857282195307, 81),\n",
        "       ('erfurt', 0.17456459953225742, 81),\n",
        "       ('stuttgart', 0.17057759020062996, 81)], \n",
        "      dtype=[('word', 'S29'), ('metric', '<f8'), ('cluster', '<i8')])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}